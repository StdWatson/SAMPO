{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/160], Loss: -0.0000\n",
      "Epoch [2/10], Step [100/160], Loss: -0.0000\n",
      "Epoch [3/10], Step [100/160], Loss: -0.0000\n",
      "Epoch [4/10], Step [100/160], Loss: -0.0000\n",
      "Epoch [5/10], Step [100/160], Loss: -0.0000\n",
      "Epoch [6/10], Step [100/160], Loss: -0.0000\n",
      "Epoch [7/10], Step [100/160], Loss: -0.0000\n",
      "Epoch [8/10], Step [100/160], Loss: -0.0000\n",
      "Epoch [9/10], Step [100/160], Loss: -0.0000\n",
      "Epoch [10/10], Step [100/160], Loss: -0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "input_parameters = 5\n",
    "layer_size = 5\n",
    "layer_count = 3\n",
    "classification_size = 1\n",
    "learning_rate = 0.001\n",
    "graph_stat = Variable(torch.ones(input_parameters, layer_size))\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear0 = torch.nn.Linear(layer_size, layer_size)\n",
    "        self.linear1 = torch.nn.Linear(layer_size, layer_size)\n",
    "        self.linear2 = torch.nn.Linear(layer_size, classification_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear0(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = NeuralNet()\n",
    "\n",
    "result = model(graph_stat)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def load_dataset(filename: str) -> tuple[list, list]:\n",
    "    df = pandas.read_csv(filename)\n",
    "    df.reset_index()\n",
    "    return [torch.Tensor(v) for v in df.drop('label', axis=1).to_numpy()[:, 1:]], \\\n",
    "        [torch.Tensor([v]) for v in df['label'].to_numpy()]\n",
    "\n",
    "\n",
    "dataset, dataset_labels = load_dataset('dataset.csv')\n",
    "\n",
    "bound = int(len(dataset) * 0.8)\n",
    "train = list(zip(dataset[:bound], dataset_labels[:bound]))\n",
    "test = list(zip(dataset[bound:], dataset_labels[bound:]))\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (image, label) in enumerate(train):\n",
    "        # Move tensors to the configured device\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sampo.schemas.graph import WorkGraph\n",
    "\n",
    "\n",
    "def metric_vertex_count(wg: WorkGraph) -> float:\n",
    "    return wg.vertex_count\n",
    "\n",
    "def metric_min_children(wg: WorkGraph) -> float:\n",
    "    return min((len(node.children) for node in wg.nodes if node.children))\n",
    "\n",
    "def metric_max_children(wg: WorkGraph) -> float:\n",
    "    return max((len(node.children) for node in wg.nodes if node.children))\n",
    "\n",
    "def metric_min_parents(wg: WorkGraph) -> float:\n",
    "    return min((len(node.parents) for node in wg.nodes if node.parents))\n",
    "\n",
    "def metric_max_parents(wg: WorkGraph) -> float:\n",
    "    return max((len(node.parents) for node in wg.nodes if node.parents))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NeuralNet ------ Multi-Agency\n",
      "Result | Time ---- Result | Time\n",
      "1522 | 0.14272284507751465 ---- 1523 | 1.0730080604553223 ------------- 751% time win | 0% result loss\n",
      "1010 | 0.09198164939880371 ---- 1011 | 0.5129594802856445 ------------- 557% time win | 0% result loss\n",
      "Prediction mismatch\n",
      "1208 | 0.10194587707519531 ---- 1206 | 0.5308809280395508 ------------- 520% time win | 0% result loss\n",
      "345 | 0.036889076232910156 ---- 346 | 0.16800856590270996 ------------- 455% time win | 0% result loss\n",
      "Prediction mismatch\n",
      "1045 | 0.09304475784301758 ---- 1017 | 0.40797924995422363 ------------- 438% time win | 2% result loss\n",
      "1125 | 0.10598325729370117 ---- 1126 | 0.571998119354248 ------------- 539% time win | 0% result loss\n",
      "1359 | 0.1515965461730957 ---- 1360 | 0.8186850547790527 ------------- 540% time win | 0% result loss\n",
      "455 | 0.04587817192077637 ---- 456 | 0.1875016689300537 ------------- 408% time win | 0% result loss\n",
      "1231 | 0.12865686416625977 ---- 1232 | 0.773496150970459 ------------- 601% time win | 0% result loss\n",
      "402 | 0.03390979766845703 ---- 403 | 0.12199735641479492 ------------- 359% time win | 0% result loss\n",
      "980 | 0.09897947311401367 ---- 981 | 0.5686237812042236 ------------- 574% time win | 0% result loss\n",
      "503 | 0.04138994216918945 ---- 504 | 0.16149401664733887 ------------- 390% time win | 0% result loss\n",
      "1084 | 0.10821652412414551 ---- 1085 | 0.5016717910766602 ------------- 463% time win | 0% result loss\n",
      "1262 | 0.10571765899658203 ---- 1263 | 0.5595049858093262 ------------- 529% time win | 0% result loss\n",
      "1420 | 0.12267208099365234 ---- 1421 | 0.6588089466094971 ------------- 537% time win | 0% result loss\n",
      "1093 | 0.09924101829528809 ---- 1094 | 0.5994338989257812 ------------- 604% time win | 0% result loss\n",
      "1050 | 0.10870862007141113 ---- 1051 | 0.5462136268615723 ------------- 502% time win | 0% result loss\n",
      "957 | 0.09075784683227539 ---- 958 | 0.46236705780029297 ------------- 509% time win | 0% result loss\n",
      "931 | 0.10392451286315918 ---- 932 | 0.5749995708465576 ------------- 553% time win | 0% result loss\n",
      "473 | 0.036463022232055664 ---- 474 | 0.13915681838989258 ------------- 381% time win | 0% result loss\n",
      "436 | 0.033910274505615234 ---- 437 | 0.1303725242614746 ------------- 384% time win | 0% result loss\n",
      "1599 | 0.143202543258667 ---- 1600 | 0.8397564888000488 ------------- 586% time win | 0% result loss\n",
      "Prediction mismatch\n",
      "1472 | 0.11569023132324219 ---- 1349 | 0.7053301334381104 ------------- 609% time win | 8% result loss\n",
      "1228 | 0.1275029182434082 ---- 1229 | 0.6489627361297607 ------------- 508% time win | 0% result loss\n",
      "1308 | 0.11269903182983398 ---- 1309 | 0.6622300148010254 ------------- 587% time win | 0% result loss\n",
      "1279 | 0.10671401023864746 ---- 1280 | 0.5595016479492188 ------------- 524% time win | 0% result loss\n",
      "1078 | 0.10671496391296387 ---- 1079 | 0.5702023506164551 ------------- 534% time win | 0% result loss\n",
      "1306 | 0.10313248634338379 ---- 1307 | 0.5517330169677734 ------------- 534% time win | 0% result loss\n",
      "1196 | 0.11647486686706543 ---- 1197 | 0.5962278842926025 ------------- 511% time win | 0% result loss\n",
      "1435 | 0.1515944004058838 ---- 1436 | 0.796872615814209 ------------- 525% time win | 0% result loss\n",
      "519 | 0.03989386558532715 ---- 520 | 0.14561104774475098 ------------- 364% time win | 0% result loss\n",
      "419 | 0.03191423416137695 ---- 420 | 0.11269783973693848 ------------- 353% time win | 0% result loss\n",
      "1060 | 0.09932732582092285 ---- 1061 | 0.5245981216430664 ------------- 528% time win | 0% result loss\n",
      "445 | 0.03790020942687988 ---- 446 | 0.15259265899658203 ------------- 402% time win | 0% result loss\n",
      "1087 | 0.11268258094787598 ---- 1088 | 0.5637004375457764 ------------- 500% time win | 0% result loss\n",
      "1107 | 0.10429048538208008 ---- 1108 | 0.5664832592010498 ------------- 543% time win | 0% result loss\n",
      "Prediction mismatch\n",
      "1448 | 0.14068102836608887 ---- 1415 | 0.835841178894043 ------------- 594% time win | 2% result loss\n",
      "1159 | 0.09559988975524902 ---- 1160 | 0.4523499011993408 ------------- 473% time win | 0% result loss\n",
      "1300 | 0.11946582794189453 ---- 1301 | 0.605032205581665 ------------- 506% time win | 0% result loss\n",
      "1122 | 0.09674215316772461 ---- 1123 | 0.4597954750061035 ------------- 475% time win | 0% result loss\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from sampo.scheduler.multi_agency.multi_agency import Agent, Manager\n",
    "from sampo.scheduler.topological.base import TopologicalScheduler\n",
    "from sampo.scheduler.heft.base import HEFTScheduler, HEFTBetweenScheduler\n",
    "import time\n",
    "from sampo.generator.base import SimpleSynthetic\n",
    "from sampo.scheduler.multi_agency.block_graph import BlockGraph, BlockNode\n",
    "\n",
    "ss = SimpleSynthetic(256)\n",
    "schedulers = [HEFTScheduler(), HEFTBetweenScheduler(), TopologicalScheduler()]\n",
    "contractors = [ss.contractor(10)]\n",
    "\n",
    "print('   NeuralNet ------ Multi-Agency')\n",
    "print('Result | Time ---- Result | Time')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(len(test)):\n",
    "        wg = ss.work_graph(top_border=100)\n",
    "        bg = BlockGraph([BlockNode(wg)])\n",
    "        # encode graph\n",
    "        encoding = torch.Tensor([metric_vertex_count(wg),\n",
    "                                 metric_min_children(wg),\n",
    "                                 metric_max_children(wg),\n",
    "                                 metric_min_parents(wg),\n",
    "                                 metric_max_parents(wg)])\n",
    "\n",
    "        nn_start = time.time()\n",
    "        # predict scheduler\n",
    "        outputs = model(encoding)\n",
    "        _, predicted = torch.max(outputs.data, 0)\n",
    "        # use predicted scheduler to generate schedule\n",
    "        nn_result = schedulers[predicted].schedule(wg, contractors).execution_time\n",
    "        nn_time = time.time() - nn_start\n",
    "\n",
    "        agents = [Agent(str(scheduler), scheduler, deepcopy(contractors)) for scheduler in schedulers]\n",
    "        manager = Manager(agents)\n",
    "        ma_start = time.time()\n",
    "        # run MA scheduler selection\n",
    "        block_schedule = list(manager.manage_blocks(bg).values())\n",
    "        ma_result = max(v.end_time for v in block_schedule)\n",
    "        ma_time = time.time() - ma_start\n",
    "\n",
    "        if schedulers[predicted] != block_schedule[0].agent.scheduler:\n",
    "            print('Prediction mismatch')\n",
    "\n",
    "        print(f'{nn_result} | {nn_time} ---- {ma_result} | {ma_time} ------------- {int(ma_time / nn_time * 100)}% time win | {int((1 - ma_result / nn_result) * 100)}% result loss')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
