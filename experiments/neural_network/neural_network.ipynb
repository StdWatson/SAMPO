{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_parameters = 16\n",
    "layer_size = 5\n",
    "layer_count = 3\n",
    "classification_size = 3\n",
    "learning_rate = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:26:40.243406300Z",
     "start_time": "2023-08-30T14:26:40.233370800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[ 0.0702,  0.1229, -0.0518,  0.2359, -0.0319, -0.2229,  0.1273, -0.1397,\n           0.2117,  0.1238,  0.2149, -0.0037,  0.1376, -0.2249, -0.0738,  0.1205],\n         [ 0.0710, -0.1297, -0.2387,  0.0009,  0.2140,  0.0724, -0.0456,  0.0698,\n           0.1864,  0.1642, -0.0451,  0.1541, -0.2162,  0.1666,  0.0041,  0.0633],\n         [ 0.0670,  0.0949,  0.1137,  0.0395, -0.1552, -0.0542, -0.0881,  0.2164,\n          -0.2392, -0.0585,  0.0526, -0.1061, -0.0562,  0.0464, -0.1048,  0.0935],\n         [ 0.1381,  0.1717,  0.1800,  0.0055,  0.0779, -0.1923, -0.0777, -0.1017,\n           0.1346, -0.0803,  0.2414, -0.1126, -0.1839, -0.0212,  0.0895,  0.1969],\n         [ 0.1413,  0.1015, -0.1166,  0.0276,  0.1721, -0.2195, -0.0969, -0.1548,\n           0.0883,  0.2231,  0.0240, -0.1135,  0.0728, -0.1237, -0.0604,  0.1968]],\n        requires_grad=True),\n Parameter containing:\n tensor([-0.1251, -0.1201,  0.1454,  0.2311,  0.0217], requires_grad=True)]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sampo.scheduler.selection.neural_net import NeuralNet, load_dataset\n",
    "\n",
    "model = NeuralNet(input_parameters, layer_size, layer_count, classification_size)\n",
    "list(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:26:40.423526700Z",
     "start_time": "2023-08-30T14:26:40.393105900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/2250], Loss: 1.5508\n",
      "Epoch [1/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [1200/2250], Loss: 0.5534\n",
      "Epoch [1/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [1400/2250], Loss: 0.5781\n",
      "Epoch [1/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [1/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [1/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [1/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [2/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [2/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [2/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [3/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [3/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [3/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [4/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [4/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [4/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [5/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [5/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [5/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [6/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [6/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [6/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [7/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [7/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [7/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [8/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [8/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [8/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [9/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [9/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [9/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [10/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [10/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [10/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [11/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [11/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [11/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [12/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [12/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [12/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [13/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [13/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [13/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [14/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [14/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [14/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [15/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [15/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [15/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [16/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [16/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [16/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [17/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [17/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [17/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [18/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [18/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [18/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [19/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [19/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [19/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [20/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [20/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [20/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [21/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [21/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [21/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [22/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [22/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [22/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [23/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [23/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [23/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [24/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [24/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [24/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [25/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [25/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [25/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [26/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [26/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [26/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [27/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [27/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [27/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [28/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [28/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [28/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [29/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [29/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [29/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [30/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [30/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [30/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [31/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [31/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [31/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [32/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [32/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [32/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [33/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [33/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [33/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [34/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [34/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [34/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [35/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [35/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [35/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [36/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [36/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [36/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [37/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [37/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [37/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [38/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [38/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [38/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [39/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [39/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [39/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [40/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [40/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [40/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [41/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [41/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [41/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [42/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [42/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [42/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [43/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [43/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [43/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [44/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [44/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [44/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [45/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [45/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [45/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [46/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [46/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [46/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [47/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [47/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [47/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [48/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [48/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [48/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [49/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [49/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [49/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [50/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [50/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [50/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [51/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [51/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [51/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [52/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [52/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [52/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [53/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [53/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [53/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [54/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [54/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [54/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [55/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [55/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [55/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [56/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [56/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [56/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [57/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [57/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [57/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [58/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [58/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [58/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [59/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [59/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [59/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [60/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [60/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [60/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [61/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [61/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [61/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [62/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [62/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [62/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [63/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [63/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [63/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [64/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [64/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [64/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [65/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [65/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [65/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [66/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [66/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [66/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [67/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [67/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [67/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [68/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [68/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [68/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [69/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [69/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [69/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [70/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [70/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [70/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [71/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [71/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [71/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [72/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [72/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [72/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [73/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [73/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [73/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [74/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [74/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [74/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [75/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [75/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [75/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [76/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [76/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [76/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [77/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [77/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [77/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [78/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [78/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [78/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [79/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [79/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [79/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [80/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [80/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [80/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [81/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [81/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [81/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [82/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [82/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [82/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [83/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [83/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [83/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [84/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [84/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [84/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [85/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [85/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [85/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [86/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [86/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [86/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [87/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [87/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [87/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [88/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [88/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [88/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [89/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [89/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [89/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [90/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [90/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [90/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [91/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [91/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [91/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [92/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [92/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [92/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [93/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [93/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [93/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [94/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [94/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [94/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [95/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [95/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [95/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [96/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [96/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [96/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [97/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [97/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [97/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [98/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [98/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [98/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [99/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [99/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [99/100], Step [2200/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [100/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [200/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [300/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [400/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [500/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [600/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [700/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [800/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [900/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [1000/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1100/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1200/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1300/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1400/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1500/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [1600/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [1700/2250], Loss: 1.1344\n",
      "Epoch [100/100], Step [1800/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [1900/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [2000/2250], Loss: 1.2178\n",
      "Epoch [100/100], Step [2100/2250], Loss: 0.9610\n",
      "Epoch [100/100], Step [2200/2250], Loss: 1.1344\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([[ 0.1069,  0.1460, -0.0022,  0.2634,  0.0178, -0.1918,  0.1584, -0.1053,\n           0.2493,  0.1505,  0.2430,  0.0284,  0.1678, -0.1975, -0.0486,  0.1325],\n         [ 0.0380, -0.1496, -0.2851, -0.0233,  0.1676,  0.0444, -0.0736,  0.0382,\n           0.1514,  0.1394, -0.0708,  0.1247, -0.2421,  0.1449, -0.0123,  0.0960],\n         [ 0.0670,  0.0949,  0.1137,  0.0395, -0.1552, -0.0542, -0.0881,  0.2164,\n          -0.2392, -0.0585,  0.0526, -0.1061, -0.0562,  0.0464, -0.1048,  0.0935],\n         [ 0.2430,  0.2600,  0.2973,  0.1004,  0.1952, -0.0921,  0.0226,  0.0020,\n           0.2400,  0.0142,  0.3396, -0.0108, -0.0947,  0.0045,  0.0669,  0.1761],\n         [ 0.2038,  0.1505, -0.0443,  0.0812,  0.2444, -0.1617, -0.0390, -0.0957,\n           0.1464,  0.2715,  0.0769, -0.0567,  0.1308, -0.0767, -0.0310,  0.1968]],\n        requires_grad=True),\n Parameter containing:\n tensor([-0.0940, -0.1481,  0.1454,  0.3313,  0.0796], requires_grad=True)]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     print(f'Loop {i}/10')\n",
    "x_train, x_test, y_train, y_test = load_dataset('dataset.csv')\n",
    "model.fit(x_train, y_train, 100)\n",
    "list(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:26:41.513226200Z",
     "start_time": "2023-08-30T14:26:41.055213300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 1., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([1., 0., 0.]),\n tensor([0., 0., 1.]),\n tensor([0., 1., 0.]),\n tensor([0., 1., 0.])]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:26:42.398321100Z",
     "start_time": "2023-08-30T14:26:42.383354900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNet' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m(x_test, y_test)\n",
      "File \u001B[1;32m~\\PycharmProjects\\sampo\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NeuralNet' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:27:06.443447700Z",
     "start_time": "2023-08-30T14:27:06.413133400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sampo.scheduler.selection.neural_net import NeuralNet\n",
    "\n",
    "train_dataset = pd.read_csv('dataset.csv', index_col='index')\n",
    "for col in train_dataset.columns[:-1]:\n",
    "    train_dataset[col] = train_dataset[col].apply(lambda x: float(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:27:25.722995700Z",
     "start_time": "2023-08-30T14:27:25.673218200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1     2          3     4    5    6    7      8      9  \\\nindex                                                                        \n0      127.0  0.859823  46.0  29.814961  46.0  1.0  1.0  3.0   93.0  424.0   \n2      190.0  0.906255  68.0  30.084211  68.0  1.0  1.0  4.0  138.0  527.0   \n1      112.0  1.121457  34.0  35.151786  34.0  1.0  1.0  3.0   69.0  412.0   \n3      182.0  0.977690  66.0  33.574176  66.0  1.0  1.0  3.0   66.0  356.0   \n5      156.0  0.719637  58.0  28.128205  58.0  1.0  1.0  3.0   94.0  400.0   \n4      127.0  1.049286  41.0  32.751969  41.0  1.0  1.0  3.0   71.0  482.0   \n6      191.0  0.644718  66.0  27.039267  66.0  1.0  1.0  3.0   90.0  646.0   \n7      133.0  0.757486  38.0  29.436090  38.0  1.0  1.0  3.0   77.0  560.0   \n8      195.0  0.614343  78.0  27.212821  78.0  1.0  1.0  3.0   78.0  408.0   \n\n           10      11     12  label  \nindex                                \n0       729.0   881.0  258.0      0  \n2       892.0   976.0  292.0      0  \n1       667.0   883.0  226.0      0  \n3      1260.0  1344.0  900.0      1  \n5       800.0   860.0  356.0      1  \n4       749.0  1009.0  242.0      1  \n6      1248.0  1568.0  580.0      2  \n7       865.0  1193.0  274.0      2  \n8      1228.0  1304.0  804.0      2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>127.0</td>\n      <td>0.859823</td>\n      <td>46.0</td>\n      <td>29.814961</td>\n      <td>46.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>93.0</td>\n      <td>424.0</td>\n      <td>729.0</td>\n      <td>881.0</td>\n      <td>258.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>190.0</td>\n      <td>0.906255</td>\n      <td>68.0</td>\n      <td>30.084211</td>\n      <td>68.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>138.0</td>\n      <td>527.0</td>\n      <td>892.0</td>\n      <td>976.0</td>\n      <td>292.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>112.0</td>\n      <td>1.121457</td>\n      <td>34.0</td>\n      <td>35.151786</td>\n      <td>34.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>69.0</td>\n      <td>412.0</td>\n      <td>667.0</td>\n      <td>883.0</td>\n      <td>226.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>182.0</td>\n      <td>0.977690</td>\n      <td>66.0</td>\n      <td>33.574176</td>\n      <td>66.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>66.0</td>\n      <td>356.0</td>\n      <td>1260.0</td>\n      <td>1344.0</td>\n      <td>900.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>156.0</td>\n      <td>0.719637</td>\n      <td>58.0</td>\n      <td>28.128205</td>\n      <td>58.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>94.0</td>\n      <td>400.0</td>\n      <td>800.0</td>\n      <td>860.0</td>\n      <td>356.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>127.0</td>\n      <td>1.049286</td>\n      <td>41.0</td>\n      <td>32.751969</td>\n      <td>41.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>71.0</td>\n      <td>482.0</td>\n      <td>749.0</td>\n      <td>1009.0</td>\n      <td>242.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>191.0</td>\n      <td>0.644718</td>\n      <td>66.0</td>\n      <td>27.039267</td>\n      <td>66.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>90.0</td>\n      <td>646.0</td>\n      <td>1248.0</td>\n      <td>1568.0</td>\n      <td>580.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>133.0</td>\n      <td>0.757486</td>\n      <td>38.0</td>\n      <td>29.436090</td>\n      <td>38.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>77.0</td>\n      <td>560.0</td>\n      <td>865.0</td>\n      <td>1193.0</td>\n      <td>274.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>195.0</td>\n      <td>0.614343</td>\n      <td>78.0</td>\n      <td>27.212821</td>\n      <td>78.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>78.0</td>\n      <td>408.0</td>\n      <td>1228.0</td>\n      <td>1304.0</td>\n      <td>804.0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_parameters = 14\n",
    "layer_size = 5\n",
    "layer_count = 3\n",
    "classification_size = 3\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model = NeuralNet(input_parameters, layer_size, layer_count, classification_size, learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:27:26.193024800Z",
     "start_time": "2023-08-30T14:27:26.153299100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.5171, Accuracy: 0/3 (0.00%)\n",
      "\n",
      "Test set: Average loss: 0.5171, Accuracy: 2/3 (66.67%)\n",
      "\n",
      "Test set: Average loss: 0.5171, Accuracy: 0/3 (0.00%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0, 66.66666666666667, 0.0]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T14:27:27.964020500Z",
     "start_time": "2023-08-30T14:27:26.913334700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1643409996.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[1], line 4\u001B[1;36m\u001B[0m\n\u001B[1;33m    model=model,\u001B[0m\n\u001B[1;37m         ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sampo.scheduler.selection.validation import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "s = cross_val_score(train_dataset=train_dataset,\n",
    "                    target_column='label',\n",
    "                    scorer=accuracy_score,\n",
    "                    model=model,\n",
    "                    epochs=100,\n",
    "                    folds=10,\n",
    "                    shuffle=True,\n",
    "                    random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T08:15:20.510711200Z",
     "start_time": "2023-09-04T08:15:20.493710900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.333333333333336, 40.0, 33.333333333333336, 40.0, 40.0, 46.666666666666664, 20.0, 60.0, 33.333333333333336, 40.0]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T16:34:05.388475Z",
     "start_time": "2023-08-28T16:34:05.372698900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
